{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <center> ADQUISICION Y PREPROCESAMIENTO <center>\n",
    "##  <center> RETINA <center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONTEXTO\n",
    "\n",
    "### Sobre el proyecto\n",
    "Nuestro proyecto consiste en detectar a partir de la videocaptura de un rostro la ubicacion de los ojos, hacerle un seguimiento y posteriormente evaluar diferentes acciones que el usuario pueda realizar a traves de los movimientos que realice con los ojos. Es importante mencionar que la videocaptura se realizara por medio de un celular o camara para computadores por lo que utilizamos como referencia una camara generica Huawei con las siguientes caracteristicas:\n",
    "\n",
    "8 MP, f/2.0\n",
    "\n",
    "Estos parametros son invariables y debemos trabajar con ellos por medio de preprocesamiento para poder llegar a una etapa de segmentacion exitosa a futuro.\n",
    "\n",
    "### Sobre la adquisicion y el preprocesmiento\n",
    "Idealmente nosotros haremos en una etapa posterior un proceso de Machine Learning que nos permita separar los ojos del fondo y todos los elementos externos que puedan generar ruido, por esta razon partiremos para la adquisicion y el procesamiento de la base anteriormente mensionada y nos enfocaremos en tratar imagenes y videos que contengan unicamente el ojo y sus alrederoros mas cercanos para determinar los mejores filtros y funciones a utilizar. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADQUISICION\n",
    "\n",
    "### Metodo de adquisicion\n",
    "\n",
    "La adquisicon sera un proceso sencillo puesto que no podemos reparar en las condiciones ambientales, las caracteristicas de los elementos de obtencion o la calidad final de la imagen, es por esta razon que hemos obtado por un proceso de Machine Learning para segmentar de la imagen completa solamente lo que nos interesa, la adquisicion se hara atraves de camaras de celulares o camaras de portatiles o usb, estas camaras tienen una gran variedad de caracteristicas distintas, estas camaras nos entregaran video a que trataremos a 30fps frame por frame. \n",
    "\n",
    "Las imagenes que obtendremos del rostro y los ojos sera paralela al rostro como se muestra en la figura 1. \n",
    "\n",
    "<center><i>Figura 1. Esquema de imagenes a obtener.</i></center>\n",
    "<img src=\"entrega/1.png\" alt=\"1\" style=\"width:700px\">\n",
    "\n",
    "y una vez se haya aplicado el proceso de Machine Learning y se obtenga de la imagen solo aquello que nos interesa tendremos una imagen del estilo de la figura 2.\n",
    "\n",
    "<center><i>Figura 2. Segmentacion por Machine Learning.</i></center>\n",
    "<img src=\"entrega/2.png\" alt=\"2\" style=\"width:300px\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adquisicion de las imagenes e importacion a python\n",
    "#### Función de captura\n",
    "<p>Esta función captura la webcam del computador y posteriormente se le aplica un filtro a cada frame del video capturado.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def captureAndApplyFilter(f, fparams=[]):\n",
    "    \n",
    "    # Get a reference to webcam #0 (the default one)\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        # Grab a single frame of video\n",
    "        ret, frame = video_capture.read()\n",
    "        frame = cv2.cvtColor( frame, cv2.COLOR_BGR2GRAY )\n",
    "    \n",
    "        # Apply a filter to the frame\n",
    "        res = f(frame,*fparams)\n",
    "\n",
    "        cv2.imshow('Video', res)\n",
    "\n",
    "        # Hit 'q' on the keyboard to quit!\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release handle to the webcam\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print('Released Video Resource')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESAMIENTO\n",
    "\n",
    "En el prepocesamiento utilizamos distintos tipos de filtros con el fin de resaltar el iris para que en una posterior etapa de segmentacion sea mucho mas facil de reconocer.\n",
    "\n",
    "### Parámetros\n",
    "<ul>\n",
    "<li>Función filtro que se le va a aplicar a cada frame.</li>\n",
    "<li>Array, en orden, con los parámetros de la función filtro.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones filtro\n",
    "<p>Funciones que reciben una imagen y devuelven una imagén modificada.</p>\n",
    "\n",
    "<ul>\n",
    "<li>Sin filtro</li>\n",
    "<li>Negativo</li>\n",
    "<li>Raiz con MedianBlur</li>\n",
    "<li>Thresholded</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonFilter(img): return img\n",
    "\n",
    "def negative(img):\n",
    "    img1_subtract= np.zeros(img.shape, np.uint8)\n",
    "    img1_subtract = cv2.subtract(255, img)\n",
    "    img1_subtract = cv2.subtract(img1_subtract,100)\n",
    "    return img1_subtract\n",
    "\n",
    "\n",
    "def non_linear_rootMod(img, a, b):\n",
    "    \n",
    "    img_copy = img.copy().astype(np.float32)/255.0\n",
    "    res_a = cv2.pow(img_copy,0.5)\n",
    "    res_a = cv2.multiply(res_a, a)\n",
    "    res = cv2.add(res_a,b)\n",
    "    \n",
    "    res[res<0] = 0\n",
    "    res = res*255.0\n",
    "    res[res>255] = 255\n",
    "    \n",
    "    res = res.astype(np.uint8)\n",
    "    res = cv2.medianBlur(res,5)\n",
    "    \n",
    "    return res\n",
    "\n",
    "def thresholdImg(img):\n",
    "#     th, thresholded = cv2.threshold(img,200,255,cv2.THRESH_BINARY)\n",
    "#     thresholded = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "    thresholded = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,2)\n",
    "    return thresholded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sin filtro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal\n",
    "captureAndApplyFilter(nonFilter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative\n",
    "captureAndApplyFilter(negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raiz con MedianBlur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raiz con MedianBlur\n",
    "a = 1.3\n",
    "b = -0.1\n",
    "params = [a,b]\n",
    "captureAndApplyFilter(non_linear_rootMod,params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold\n",
    "captureAndApplyFilter(thresholdImg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
